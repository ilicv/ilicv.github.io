<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head>
   <meta http-equiv="Content-Type" content="text/html; charset=windows-1250">
   <meta name="Author" content="Velibor Ilic">
   <meta name="KeyWords" content="neuronske, mreze, neural, network, networks, ann, ann, nn, velibor, ilic, becej, ai, artificial, intelligence, vestacka, inteligencija, ekspertni, sistemi, expert, systems, fazi, logika, fuzzy, logic,  ocr, prepoznavanje, cirilicnih slova, optical, character, recognition,">
   <meta name="revisit-after" content="15 days">
   <meta name="ROBOTS" content="ALL">
   <meta name="Description" content="History of neural networks. What are neural networks. Model of artificial neuron, model of artificial neural network. Differences between classical algorithms and neural networks.Istorijat razvoja neuronskih mreza. Sta su neuronske mreze? Model vestackog neurona, model neuronske mreze. Razlike izmedju neuronskih mreza i klasicnih racunara i primene.">
   <title>Neuronske Mreze</title>

  <link rel="stylesheet" type="text/css" href="my.css" media="screen,projection">
</head>
<body>
<center>
<script type="text/javascript"><!--
google_ad_client = "pub-0327694111200541";
/* 728x15, created 10/17/09 */
google_ad_slot = "8046978970";
google_ad_width = 728;
google_ad_height = 15;
//-->
</script>
<script type="text/javascript"
src="http://pagead2.googlesyndication.com/pagead/show_ads.js">
</script>

<table width=100% cellpadding="0" cellspacing="0">
<tr>
<td width="30"></td>
<td align="left" background="header_bg.png">
<img src="header.png"><br>




<table width="100%" bgcolor="#FFFFFF" border="1" cellpadding="0" cellspacing="0">
  <tbody><tr>
    <td>
          

<table width="100%" cellpadding="0" cellspacing="0">
<tbody><tr valign="top">

<td class="menu_back" width="150" align="left"> <!--menu-->
<table cellpadding="2" cellspacing="0">
<tbody><tr valign="top">
<td>

<a href="index.html">Home</a><br>
<a href="VeliborCV.html">Biografija</a><br>
<hr width="135" align="center">

<a href="automatsko_trgovanje.html">Automatsko trgovanje</a><br>
<a href="PProgrami.htm">Poslovni programi</a><br>
<a href="recnik.html">Reènik</a><br>
<a href="PlanB.htm">PlanB</a><br>
<hr width="135" align="center">

<a href="AI_index.htm">Veštaèka inteligencija</a><br>
<a href="neuro.html">Neuronske mreže</a><br>
<a href="ANN.html">ANN</a><br>
<a href="FLAlg.html">Force learn algoritam</a><br>
<a href="NeuroVCL.html">NeuroVCL</a><br>
<a href="agenti.html">Agenti</a><br>
<a href="enaa.html">ENAA</a><br>

<hr width="135" align="center">

<a href="ocr_opis.html">OCR</a><br>
<a href="ocr.html">OCR soft</a><br>
<hr width="135" align="center">

<a href="scada.html">Izrada SCADA</a><br>
<a href="smartscada.html">SmartSCADA</a><br>
<hr width="135" align="center">

<a href="https://www.dropbox.com/s/a8p6nygmuqemzbf/nanotehnlogija.pdf?dl=0">Nanotehnologija</a><br>
<a href="linkovi.htm">Linkovi</a><br>
<a href="free.html">Free Download</a>
<br>
<hr width="135" align="center">
<br>
<br>
<center>
<script type="text/javascript"><!--
google_ad_client = "pub-0327694111200541";
/* 120x90, created 10/17/09 */
google_ad_slot = "0178951326";
google_ad_width = 120;
google_ad_height = 90;
//-->
</script>
<script type="text/javascript"
src="http://pagead2.googlesyndication.com/pagead/show_ads.js">
</script>


<br>
<br>
<p style="margin-top: 0; margin-bottom: 0">
<a href="http://usa.nedstatbasic.net/cgi-bin/viewstat?name=ilicv"><img
src="http://usa.nedstatbasic.net/cgi-bin/nedstat.gif?name=ilicv"
border=0 alt="" nosave width=22 height=22></a>
</center>



</td></tr></tbody>
</table>
</td> <!--menu-->


<td valign="top" align="left"> <!--main-->
<table width="100%" border="0" cellpadding="0" cellspacing="0">
 <tbody><tr>
   <td>




<td valign="top" width="100%" align="left"> <!--main-->
<table width="100%" border="0" cellpadding="0" cellspacing="0">
 <tbody><tr>
   <td>


<table width="100%" border="0" cellpadding="0" cellspacing="3">
<tbody><tr>

<td valign="top" align="left"> <!--main left-->

<table BORDER CELLSPACING=0 CELLPADDING=0 COLS=1 WIDTH="100%" >
<tr>
<td VALIGN=TOP BGCOLOR="#333333">
<center><font size="+2" face="Arial,Helvetica" color="#EDE8DE">
<b>Neuronske Mreže</b>
</font></center></td>
</tr>
</table>
<br> 

<p><b>Autor:</b> <a href="VeliborCV.html">Velibor Iliæ</a>

<p><b>Abstrakt: </b>Istorijat razvoja neuronskih mreža. Šta su neuronske mreže? Model veštaèkog neurona, model neuronske mreže. Razlike izmeðu neuronskih mreža i klasiènih raèunara i primene.

<p><b>Abstract: </b>History of neural networks. What are neural networks. Model of artificial neuron, model of artificial neural network. Differences between classical algorithms and neural networks.
<p><b>Datum izrade</b>: Novembar, 1999

<p>
<p>
<hr width="97%">
<table BORDER=0 CELLSPACING=0 CELLPADDING=0 >
<tr>
<td>
<a href="http://twitter.com/velibor" class="twitter-follow-button" data-show-count="false">Follow @velibor</a>
<script src="http://platform.twitter.com/widgets.js" type="text/javascript"></script>
&nbsp; &nbsp; &nbsp;
<td>
<a title="Velibor Ilic" href="http://www.researchgate.net/profile/Velibor_Ilic/"><img src="http://www.researchgate.net/images/public/profile_image_my_profile_big.png" alt="Velibor Ilic" /></a>
</td>
</tr>
</table>
<hr width="97%">
<p>

<table class="header_large" width="450" border="0"><tbody><tr><td cellpadding="10" cellspacing="10" align="left">
<a NAME="Sadrzaj"></a>Sadržaj
</td></tr></tbody></table>

<a href="#Istorijat">Istorijat neuronskih mreža</a><br>
<a href="#Sta su to NM">Šta su neuronske mreže</a><br>
<a href="#Model neurona">Model veštaèkog neurona</a><br>
<a href="#Model mreze">Model neuronske mreže</a><br>
<a href="#Aktivacione funkcije">Aktivacione funkcije</a><br>
<a href="#Tezinski koeficijenti">Težinski koeficijenti</a><br>
<a href="#Obucavanje NM">Obuèavanje neuronskih mreža</a><br>
<a href="#Realizacija">Realizacija neuronskih mreža</a><br>
<a href="#Podela">Podela neuronskih mreža</a><br>
<a href="#Mogucnosti">Moguænosti neuronskih mreža</a><br>
<a href="#Razlike">Razlike izmeðu neuronskih mreža i klasiènih raèunara</a><br>
<a href="#Nacini implementacije">Naèini implementacije neuronskih mreža</a><br>
<a href="#Domeni">Domeni primene</a><br>
<a href="ANN.html">ANN - program za obuèavanje neuronskih mreža</a><br>
<a href="ocr.html">OCR - program za prepoznavanje æiriliènih slova primenom neuronskih mreža</a>

<p>

<table class="header_large" width="450" border="0"><tbody><tr><td cellpadding="10" cellspacing="10" align="left">
<a NAME="Istorijat"></a>Istorijat neuronskih mreža
</td></tr></tbody></table>

Poèetak neuro-raèunarstva obièno se vezuje za 1943. godinu i èlanak Warrena McCullocha i Waltera Pittsa “Logièki raèun ideja svojstvenih nervnoj aktivnosti”. Ovaj èlanak je èesto citiran. Kibernetièar Norbert Winer i matematièar John von Neumann su smatrali da bi istraživanja na polju raèunarstva, inspirisana radom ljudskog mozga, mogla biti izuzetno zanimljiva.

<br>Knjiga Donalda Hebb-a iz 1949. godine “The Organization of behavior” (Organizacija ponašanja) iskazuje ideju da je klasièno psihološko uslovljeno ponašanje prisutno kod svih životinja, jer je ono svojstvo neurona. Ova ideja nije bila nova, ali ju je Hebb više
razradio od prethodnika, predlažuæi odreðeni zakon uèenja za sinapse, a pomoæu njega je izveo kvalitativno objašnjenje nekih eksperimentalnih rezultata iz psihologije.

<p>Poèetkom pedesetih godina, najviše uticaja na dalji razvoj neuronskih mreža je imao rad Marvin Minsky-a koji je u tom periodu konstruisao neuroraèunar pod imenom Snark (1951). Frank Rosenblatt je zaslužan za otkriæe jednoslojne neuronske mreže, zvane perceptron. Ovaj raèunar je mogao uspešno da podešava težinske koeficijente, meðutim ovaj raèunar nije postigao znaèajnije praktiène rezultate. Tek krajem pedesetih godina (1957-1958), Frank Rosenblatt i Charles Wightman sa svojim saradnicima su uspeli da razviju raèunar pod nazivom Mark I koji predstavlja prvi neuroraèunar. Nešto posle Rosenblatta, Bernard Widrow je sa svojim studentima (najpoznatiji je Ted Hoff, kasnije tvorac mikroprocesora) razradio novi tip “neurona” - ADALINE (ADAptivini LINearni Element, prenosna funkcija f(x)=x) i odgovarajuæi zakon uèenja.

<p>U periodu od 1950-tih do ranih 1960-tih godina napisano je nekoliko knjiga i osnovano nekoliko kompanija koje se bave neuroraèunarima. Meðutim, sredinom 1960-tih godina došlo je do zastoja zbog dva oèigledna problema. Prvo, veæina istraživaèa je prišla problemu sa kvalitativne i eksperimentalne strane, zanemarujuæi analitièki pristup. Drugo, poèetni entuzijazam je bio toliko jak da su uveliko publikovana predviðanja da nas od veštaèkog mozga deli samo nekoliko godina istraživanja. Ovakav zanos je dalje diskreditovao ovu oblast i odbio veliki broj istraživaèa. Mnogi od ovih ljudi su napustili neuroraèunarstvo i prešli u srodna polja.

<p>Sredinom 1960-ih godina je pristup rešavanja problema neuronskih mreža okarakterisan kao pogrešan, nakon što Marvin Minsky i Seyour Papert u knjizi “Perceptrons” objavljuju matematièki dokaz da jednoslojna neuronska mreža “Perceptron” ne može da nauèi funkciju XOR,
uz pretpostavku da dodavanjem više slojeva neurona taj problem neæe biti prevaziðen. Taèno je da neuron nije u stanju da izvede pomenutu funkciju, ali za iole složeniju mrežu od nekoliko neurona to predstavlja veoma jednostavan zadatak. Njihov dokaz je diskreditovao istraživanja neuronskih mreža, a finansiranja su preusmerena na druge oblasti <a href="ai_index.htm">veštaèke inteligencije</a>.

<p>U periodu izmeðu 1967. do 1982. godine pojavljuju se istraživaèi koji daju znaèajan doprinos razvoju ove oblasti kao što su Teuvo Kohonen, Kunihiko Fukushima i Stephnen Grossberg. Naroèito se istakao Teuvo Kohonen, koji je otkrio nekoliko tipova neuronskih mreža koje su po njemu dobile naziv. U ovom periodu se pojavio i backpropagation algoritam. U radu na ovom algoritmu su se posebno istakli sledeæi naèunici: Amari (1967.) dodaje unutrašnje slojeve perceptronskoj mreži, Bryson i Ho (1969.) razvijaju algoritam slièan backpropagation algoritmu, Werbos (1974) nezavisno od prethodnika razvija backpropagation algoritam, a Parker (1982) unapreðuje backpropagation algoritam. Poèetkom 80-ih, amerièka vojna agencija DARPA (Agencija za odbrambene istraživaèke projekte) postala je zainteresovana za NM i finansiranja su ponovo zapoèela. Sredinom 80-tih, poznati fizièar John Hopfield dao je veliki doprinos popularizaciji neuronskih mreža, objavljujuæi rad u kome je napravio paralelu izmeðu neuronskih mreža i odreðenih fizièkih sistema. Poèetkom devedesetih, Bart Kosko u knjizi “Neural Networks and Fuzzy Systems” dokazuje da neuronske mreže i fuzzy logika opisuju isti skup problema i samim tim otvara novu oblast koja se naziva soft computing.

<p>Rumenel, Hinton i Williams (1986) dokazuju veliku promenljivost i potencijal backpropagation algoritma. Krajem 80-tih i poèetkom 90-tih, neuronske mreže i neuro raèunarstvo se uvodi kao predmet na nekoliko elitnih univerziteta u SAD, dok se danas neuronske mreže gotovo mogu sresti na svim univerzitetima. 

<br>Iako su NM imale neobiènu istoriju, one su još uvek u ranoj fazi razvoja. Možda se sad može reæi da smo na kraju poèetka. Danas NM nalaze veoma širok spektar primena u razlièitim praktiènim oblastima.
<br>

<table class="header_large" width="450" border="0"><tbody><tr><td cellpadding="10" cellspacing="10" align="left">
<a NAME="Sta su to NM"></a>Šta su neuronske mreže
</td></tr></tbody></table>

<p>Postoje dve kategorije neuronskih mreža:
veštaèke i biološke neuronske mreže. Predstavnik bioloških neuronskih mreža je nervni sistem živih biæa. Veštaèke neuronske mreže su po strukturi, funkciji i obradi informacija sliène biološkim neuronskim mrežama, ali se radi o veštaèkim tvorevinama. Neuronska mreža u raèunarskim naukama predstavlja veoma povezanu mrežu elemenata koji obraðuju podatke. One su sposobne da izaðu na kraj sa problemima koji se tradicionalnim pristupom teško rešavaju, kao što su govor i prepoznavanje oblika. Jedna od važnijih osobina neuronskih mreža je njihova sposobnost da uèe na ogranièenom skupu primera.

<p>U ovom radu, kada se govori o neuronskim mrežama, misli se prvenstveno na “veštaèke neuronske mreže” (engleski termin Artificial Neural Networks skraæeno ANN), zbog toga što se uglavnom govori o modelima neuronskih mreža (skraæeno NM), realizovanim na raèunarima.
U struènoj literaturi, nije redak sluèaj da se izostavlja reè “veštaèke” iako se misli na njih. Biološke neuronske mreže su daleko komplikovanije od svojih matematièkih modela koji se koriste za veštaèke neuronske mreže. 

<br>NM predstavljaju sistem sastavljen od veoma velikog broja jednostavnih elemenata za obradu podataka. Ovakvi sistemi su sposobni za prikupljanje, memorisanje i korišæenje eksperimentalnog znanja. Ne postoji jedinstvena definicija neuronskih mreža. Meðutim, veæina
ljudi bi neuronske mreže definisala na sledeæi naèin:

<p>Neuronska mreža je sistem sastavljen od više jednostavnih procesora (jedinica, neurona), svaki od njih ima lokalnu memoriju u kojoj pamti podatke koje obraðuje. Te jedinice su povezane komunikacionim kanalima (vezama). Podaci koji se ovim kanalima razmenjuju su obièno numerièki. Jedinice obraðuju samo svoje lokalne podatke i ulaze koje primaju preko konekcije. Ogranièenja lokalnih operatora se mogu otkloniti tokom treninga.

<p>Veliki broj NM su nastale kao modeli bioloških neuronskih mreža. Istorijski gledano, inspiracija za razvoj NM proizilazi iz želje da se konstruiše veštaèki sistem sposoban za prefinjeno, možda “inteligentno”, izraèunavanje na slièan naèin kao što to ljudski mozak rutinski izvodi. Potencijalno, NM nam pružaju moguænost za razumevanje rada ljudskog mozga.

<br>Veštaèke neuronske mreže su kolekcija matematièkih modela koji simuliraju neke od posmatranih osobina bioloških nervnih sistema i povlaèe sliènosti sa prilagodljivim biološkim uèenjem. Saèinjene su od velikog broja meðusobno povezanih neurona (obraðujuæih
elemenata) koji su, slièno biološkim neuronima, povezani svojim vezama koje sadrže propusne (težinske) koeficijente, koje su po ulozi sliène sinapsama.

<p>Uèenje se kod bioloških sistema obavlja putem regulisanja sinaptièkih veza koje povezuju aksone i dendrite neurona. Uèenje tipiènih dogaðaja putem primera se ostvaruje preko treninga ili otkriæa do taènih setova podataka ulaza-izlaza koji treniraju algoritam
ponavljanjem podešavajuæi propusne (težinske) koeficijente veza (sinapse). Ove veze memorišu znanje neophodno za rešavanje specifiènog problema.

<p>Veæina NM ima neku vrstu pravila za “obuèavanje”, èime se koeficijenti veza izmeðu neurona podešavaju na osnovu ulaznih podataka.
Drugim reèima, NM “uèe” preko primera (kao što deca uèe da prepoznaju konkretan predmet, objekat, proces ili pojavu preko odgovarajuæih primera) i poseduju sposobnost za generalizaciju posle trening podataka.

<p>Veliki potencijal NM se nalazi u moguænosti paralelne obrade podataka, tokom izraèunavanja komponenti koje su nezavisne jedne od drugih. Neuronske mreže su sistemi sastavljeni od više jednostavnih elemenata (neurona) koji obraðuju podatke paralelno. Funkcije koje su NM u stanju da obraðuju odreðene su strukturom mreže, jaèinom konekcije a obrada podataka se izvodi u neuronima. Svaki elemenat operiše samo lokalnim informacijama. Svaki elemenat radi asinhrono, kao da nema sistemskog
sata.

<p>Iako NM postoje od 1940-tih godina, one nisu imale znaèajniju praktiènu primenu sve do 1980-tih, kada su algoritmi postali dovoljno prefinjeni za opštu upotrebu (aplikacije). Danas se NM primenjuju za rešavanje sve veæeg broja svakodnevnih problema sa znaèajnom
kompleksnošæu. U programiranju se mogu koristiti kao “generator” (engleski engine) koji je u stanju da vrši razlièita prepoznanja i klasifikacije i koji ima sposobnost da izvrši generalizaciju prilikom odluèivanja pri nepreciznim ulaznim podacima. NM nude idealno rešenje za raznovrsno klasifikovanje problema, kao što je prevoðenje teksta u govor, prepoznavanje slova, rešavanje problema za koje ne postoji algoritamsko rešenje. Pokazuju dobre rezultate prilikom predviðanja i modelovanja sistema gde fizièki procesi nisu jasni
ili su veoma kompleksni. Prednost NM leži u visokoj elastiènosti prema poremeæajima u ulaznim podacima i u sposobnosti da uèi. NM èesto uspešno rešava probleme koji su previše kompleksni za konvencionalne tehnologije (na primer, problem koji nema algoritamsko rešenje ili za koji je algoritam previše komplikovan da bi bio pronaðen) i one su èesto dobra pratnja problemima koje ljudi rešavaju.
<br>

<table class="header_large" width="450" border="0"><tbody><tr><td cellpadding="10" cellspacing="10" align="left">
<a NAME="Model neurona"></a>Model veštaèkog neurona
</td></tr></tbody></table>

<p>Veštaèki neuroni, kao i biološki, imaju jednostavnu strukturu i imaju sliène funkcije kao i biološki neuroni. Telo
neurona se naziva èvor ili jedinica.

<center><img SRC="s_neuron.gif" BORDER=2 height=175 width=226></center>

<i>u<sub>1..n</sub></i> – ulazni podaci<br>
<i>w<sub>1..n</sub></i> – težinski koeficijenti<br>
<i>f( )</i> – aktivaciona funkcija<br>
<i>i</i> – izlazni podatak<br>

<table class="header_large" width="450" border="0"><tbody><tr><td cellpadding="10" cellspacing="10" align="left">
<a NAME="Model mreze"></a>Model neuronske mreže
</td></tr></tbody></table>


Neuronsku mrežu èine:
<ul>
<li>arhitektura (topologija) mreže, odnosno šema vezivanja neurona</li>
<li>prenosna funkcija neurona</li>
<li>zakoni uèenja</li>
</ul>

Arhitekturu veštaèke neuronske mreže predstavlja specifièno ureðenje i povezivanje neurona u obliku mreže. Po arhitekturi, neuronske mreže se razlikuju prema broju neuronskih slojeva. Obièno svaki sloj prima ulaze iz prethodnog sloja, a svoje izlaze šalje narednom sloju.
Prvi sloj se naziva ulazni, poslednji je izlazni, ostali slojevi se obièno nazivaju skrivenim slojevima. Jedna od najèešæih arhitektura neuronskih mreža je mreža sa tri sloja. Prvi sloj (ulazni) je jedini sloj koji prima signale iz okruženja. Prvi sloj prenosi signale sledeæem sloju (skriveni sloj) koji obraðuje ove podatke i izdvaja osobine i šeme iz primljenih signala. Podaci koji se smatraju važnim se upuæuju izlaznom sloju, poslednjem sloju mreže. Na izlazima neurona treæeg sloja se dobijaju konaèni rezultati obrade. Složenije neuronske mreže mogu imati više skrivenih slojeva, povratne petlje i elemente za odlaganje vremena, koji su dizajnirani da omoguæe
što efikasnije odvajanje važnih osobina ili šema sa ulaznog nivoa. 
<center>

<p><img SRC="s_mreza.gif" BORDER=2 height=187 width=214>
<br>Slika Model neuronske mreže</center>

<p>Uèenje NM se svodi na uèenje iz primera kojih bi trebalo da bude što više da bi mreža mogla da se ponaša preciznije u kasnijoj eksploataciji. Proces uèenja dovodi do korigovanja sinaptièkih težina. Kada uzorci koji se predstavljaju mreži ne dovode više do promene
ovih koeficijenata, smatra se da je mreža obuèena.

<br>Postoji tri tipa obuèavanja: 
<ul>
<li>nadgledano obuèavanje - mreži se predstavljaju ulazni podaci i oèekivani izlazni podaci</li>
<li>obuèavanje ocenjivanjem - mreži se ne predstavljaju oèekivani izlazni podaci nego joj se posle izvesnog vremena predstavlja
ocena prethodnog rada. Jedan od primera je mreža koja uèi da balansira štap. Kad god štap padne, mreži se prosleðuje ocena prethodnog rada, na primer, u obliku ugaonog odstupanja štapa od ravnoteže.</li>
<li>samoorganizacija - mreži se predstavljajuiskljuèivo ulaz</li>
</ul>

<table class="header_large" width="450" border="0"><tbody><tr><td cellpadding="10" cellspacing="10" align="left">
<a NAME="Aktivacione funkcije"></a>Aktivacione funkcije
</td></tr></tbody></table>

Aktivacione funkcije neurona na skrivenim slojevima su potrebne da bi mreža bila u stanju da nauèi nelinearne funkcije. Bez nelinearnosti, neuroni skrivenih slojeva ne bi imali veæe moguænosti od obiène perceptronske mreže (koja se sastoji samo od ulaza i izlaza). Kombinovanjem linearnih funkcija se ponovo dobija linearna funkcija. Zbog toga se na izlazu neurona nalazi aktivaciona funkcija koja je najèešæe nelinearna. Ova nelinearnost èini mreže sa više slojeva naroèito moænima. Gotovo svaka nelinearna funkcija može da se koristi, mada se za backpropagation algoritam najèešæe koriste sigmoidne funkcije kao što su logistièka, arcustangens ili gausova funkcija. 

<p>Za neurone na izlaznom sloju se mogu birati aktivacione funkcije koje odgovaraju raspodeli ciljnih vrednosti. Graniène aktivacione funkcije, kakva je logistièka, su naroèito korisne kada su ciljne vrednosti ogranièene. Ali ako ciljne vrednosti nemaju ogranièene
vrednosti, bolje je da se koristi aktivaciona funkcija koja nije ogranièena. Ako su ciljne vrednosti pozitivne ali nemaju gornju granicu, najbolje je koristiti eksponencijalnu aktivacionu funkciju. Postoji izvesna prirodna povezanost izmeðu izlaznih aktivacionih funkcija i razlièite raspodele šuma koji se izuèava statistièki u kontekstu generalizacije izlaznog modela. 

<center>
<p><img SRC="s_sigma.gif" BORDER=2 height=239 width=342></center>

<p><br>
<table class="header_large" width="450" border="0"><tbody><tr><td cellpadding="10" cellspacing="10" align="left">
<a NAME="Tezinski koeficijenti"></a>Težinski koeficijenti
</td></tr></tbody></table>
Sinapse kojima biološki neuroni regulišu prohodnost odreðene putanje izmeðu aksona i dendrita, kod veštaèkih neurona se ostvaruju
preko prilagodljivih težinskih koeficijenata (engleski weight) ili težina veza. Kada se na ulaz neurona dovedu neke vrednosti i pomnože težinskim koeficijentima, dobijaju se ulazni podaci. Zbir ulaznih vrednosti neurona pomnoženih sa odgovarajuæim težinskim koeficijentima se propušta kroz aktivacionu funkciju i ta vrednost predstavlja izlaz iz neurona. Iako neuroni imaju prilièno jednostavne (linearne) funkcije, kada se povežu u višeslojnu mrežu, u stanju su da obrade veoma složene (nelinearne) funkcije.

<center>
<p><img SRC="s_neuron.gif" BORDER=2 height=175 width=226></center>

<p>Neuroni na skrivenim i izlaznim slojevima pored težinskih koeficijenata koriste i koeficijent “threshold” (“bias”) u raèunanju mrežnih ulaznih vrednosti. Koeficijent threshold se može tretirati kao dodatni težinski koeficijent na ulazu koji ima konstantnu težinu jedan.
Rukovanje ovim koeficijentom je slièno kao i za svaki drugi težinski koeficijent.

<p>Prirodni neuroni su znatno komplikovaniji od veštaèkih. Iako su veštaèki neuroni, izvedeni u VLSI tehnologiji, znatno brži od
<br>prirodnih, visok stepen meðusobne povezanosti, njihov ogroman broj i još veæi broj veza izmeðu njih, èine biološke nervne sisteme nedostižnim za današnju tehnologiju i nepotpuno razumljivim za današnju nauku. Uz to, mala je verovatnoæa da æe principijelna šema stotine
milijardi veza biti za dogledno vreme analizirana. Šta više, mi još uvek ne znamo kako da protumaèimo težinske koeficijente èak i u mrežama od samo nekoliko neurona.
<br>

<table class="header_large" width="450" border="0"><tbody><tr><td cellpadding="10" cellspacing="10" align="left">
<a NAME="Obucavanje NM"></a>Obuèavanje neuronskih mreža
</td></tr></tbody></table>


U svim biološkim neuronskim mrežama veze izmeðu pojedinaènog dendrita i aksona mogu biti pojaèane ili oslabljene. Na primer, veze mogu postati pojaèane ako se više signala šalje kroz njih, ili mogu biti oslabljene ako se signali reðe šalju kroz njih. Pojaèavanje odreðenog
neuralnog prolaza, ili veze izmeðu dendrita i aksona, rezultuje u poveæanoj verovatnoæi da æe signal biti prenesen kroz tu putanju, daljim pojaèavanjem tog puta. Putevi izmeðu neurona koji su retko korišteni polako atrofiraju, ili se umanjuju, praveæi manju verovatnoæu da æe signal biti prenesen kroz njih.

<p>Slièna situacija se pojavljuje i kod veštaèkih neurona. Podaci iz trening skupa se periodièno propuštaju kroz NM. Dobijene vrednosti na izlazu mreže se uporeðuju sa oèekivanim. Ukoliko postoji razlika izmeðu dobijenih i oèekivanih podataka, prave se modifikacije na vezama
izmeðu neurona u cilju smanjivanja razlike trenutnog i željenog izlaza. Ulazno-izlazni skup se ponovo predstavlja mreži zbog daljih podešavanja težina, pošto u prvih nekoliko koraka mreža obièno daje pogrešan rezultat. Posle podešavanja težina puta za sve ulazno izlazne šeme u trening skupu, mreža nauèi da reaguje na željeni naèin.

<p>NM je obuèena ako može taèno da rešava zadatke za koje je obuèavana. NM je sposobna da izdvoji važne osobine i šeme u klasi trening primera. Nakon obuèavanja sa odreðenom verovatnoæom, NM može da generalizuje nove ulazne podatke za koje nije obuèavana. Na primer, generalizaciju možemo videti na primeru mreže obuèavane da prepoznaje serije slika: ako na ulaz takve mreže dovedemo slike za koje mreža nije obuèavana, ona do izvesne mere može uspešno da klasifikuje takve slike.

<p>Najèešæe korišten algoritam za obuèavanje NM je backpropagation, razvijen nezavisno od strane nauènika: Paul Werbos (1974), David Parker (1984/1985), i David Rumelhart, Ronald Williams, i drugih (1985). Backpropagation uèi šeme poredeæi izlaz neuronske mreže sa željenim izlazom i raèuna greške za svaki èvor u mreži. Neuronska mreža podešava težine veza prema vrednostima greške dodeljenim za svaki èvor.
Izraèunavanje poèinje od izlaznog sloja, preko skrivenih slojeva, prema ulaznom sloju. Nakon modifikacije parametara, na mrežu se dovode novi ulazi. Obuèavanje se prekida tek kada mreža bude u stanju da daje izlaze sa zadovoljavajuæom
taènošæu.
<br>

<table class="header_large" width="450" border="0"><tbody><tr><td cellpadding="10" cellspacing="10" align="left">
<a NAME="Realizacija"></a>Realizacija neuronskih mreža
</td></tr></tbody></table>

Neuronska mreža se može realizovati na dva naèina: hardverski i softverski.

<br>Hardverska realizacija: Veštaèki neuroni su fizièki meðusobno povezani, oponašajuæi veze izmeðu bioloških neurona. Neuroni se realizuju kao jednostavna integrisana kola. <p>Softverska realizacija: NM se obièno simuliraju na tradicionalnim raèunarima, u kojima je veza izmeðu èvorova logièka (virtualna).

<p>Svaki od ovih naèina realizacije NM ima svoje prednosti kao i mane. Prednost hardverske realizacije je to što može da koristi moguænost paralelnog procesiranja informacija ukoliko se svakom neuronu u mreži dodeli po jedan procesor. Prednost softverske realizacije NM na standardnom PC raèunaru je u tome što se lakše uspostavljaju (i kasnije menjaju) veze izmeðu pojedinih neurona u mreži. U praksi se softverska realizacija koristi za testiranje, a konkretna realizacija koja se primenjuje u praksi može biti realizovana i hardverski èime se dobija na brzini.
<br>

<table class="header_large" width="450" border="0"><tbody><tr><td cellpadding="10" cellspacing="10" align="left">
<a NAME="Podela"></a>Podela neuronskih mreža
</td></tr></tbody></table>


Postoji veliki broj razlièitih realizacija neuronskih mreža, a samim tim postoji i mnogo podela. NM možemo klasifikovati prema:
<ul>
<li>broju slojeva,</li>
<li>vrsti veza izmeðu neurona,</li>
<li>vrsti obuèavanja neuronskih mreža,</li>
<li>prema smeru prostiranja informacija,</li>
<li>prema vrsti podataka.</li>
</ul>

<b>Podela neuronskih mreža prema broju slojeva</b>

<p>Postoji veliki broj razlièitih tipova NM. Jedna od najopštijih podela NM je prema broju slojeva. Mreže možemo podeliti
na:
<ul>
<li>jednoslojne i</li>
<li>višeslojne.</li>
</ul>
Danas se uglavnom izuèavaju i primenjuju višeslojne NM koje pored ulaznih i izlaznih slojeva sadrže neurone na srednjim (skrivenim)
slojevima.
<p>
<b>Podela NM prema vrsti veza</b>

<p>NM se mogu podeliti prema vrstama veza
tj. arhitekturi na:
<br>

<ul>
<li>slojevite Neuroni su rasporeðeni tako da formiraju slojeve. Na ulaz jednog neurona se dovode izlazi svih neurona sa prethodnog
sloja, a njegov izlaz se vodi na ulaze svih neurona na narednom sloju. Neuroni sa prvog (ulaznog) sloja imaju samo po jedan ulaz. Izlazi neurona sa zadnjeg (izlaznog) sloja predstavljaju izlaze mreže. Predstavnik: backpropagation algoritam.</li>

<li>potpuno povezane Izlaz jednog neurona se vodi ka ulazu svih neurona u mreži. Predstavnik: Hopfildova NM.</li>

<li>celularne Meðusobno su povezani samo susedni neuroni. Bez obzira na lokalnu povezanost, signali se prostiru i na neurone
i van susedstva zbog indirektnog prostiranja informacija. Predstavnik: CNN – Cellular Neural Network.</li>
</ul>
	
<b>Vrste obuèavanja neuronskih mreža></b>
<br>
<br>Postoje tri razlièita pristupa obuèavanju neuronskih mreža:
<ul>
<li>Nadgledano obuèavanje - Supervised training
<br>Tokom obuèavanja mreže, algoritam koji nadzire obuèavanje (supervisor) uporeðuje podatke dobivene na izlazu sa
oèekivanim podacima. Razlika izmeðu dobivenih i oèekivanih podataka se šalje proceduri za uèenje, koja koriguje težinske koeficijente mreže. Kontrolisan trening je slièan studentu koga profesor vodi u uèenju, ukazuje na greške i propuste i usmerava ka željenom cilju. Predstavnici: perceptron, backpropagation algoritam.

<p><li>Delimièno nadgledano obuèavanje
<br>Delimièno nadgledano uèenje radi na principu da mreža uèi samostalno, a povremeno dobija ocenu prethodnog rada. Primer ovakve mreže je mreža koja balansira štap. Dok je štap uspravan sve je u redu, ali kada štap padne, mreža treba
da koriguje ponašanje da bi štap ostao uspravan. Slièan sluèaj je i sa partijom šaha. Ukoliko je partija izgubljena znaèi da je došlo do greške, ali se ne zna u kome trenutku je povuèen pogrešan potez, niti koji je potez doveo do gubitka partije.

<p><li>Nenadgledano obuèavanje - Unsupervised training
<br>U nenadgledanom uèenju mreža je nezavisna. Pri obuèavanju se predstavljaju samo ulazni podaci koje NM pokušava da generalizuje i “uoèi” zajednièke osobine. Predstavnik: Kohonenove samoorganizujuæe mape.
</ul>

<p>
<b>Podela neuronskih mreža prema smeru prostiranja informacija</b>
<br>NM se mogu podeliti prema smeru prostiranja informacija kroz mrežu:

<ul>
<li>Feedforward (nerekurzivne, nerekurentne ili nepovratne) - Viši slojevi ne vraæaju informaciju u niže slojeve. Vrše prostiranje signala samo u jednom smeru (od ulaza prema izlazu) odnosno propagaciju signala.Predstavnici: Višeslojni perceptron sa primenjenim
backpropagation algoritmom.</li>
<li>(Feedback) rekurzivne ili rekurentne ili povratne - Viši slojevi vraæaju informacije nazad u niže slojeve. Izlaz iz neurona se vraæa u niže slojeve ili u isti sloj. Predstavnici: Hopfildove, Celularne NM, Kohonenove NM, dvostruko asocijativne NM. Feedback mreže imaju mnogo veæe procesne sposobnosti od Feedforward mreža.</li>
</ul>

<b>Podela neuronskih mreža prema vrsti podataka</b>
<br>Prema vrsti podataka koje obraðuju NM se mogu podeliti na:

<ul>
<li>analogne i</li>
<li>diskretne.</li>
</ul>
Ova podela se retko koristi pošto su gotovo sve NM diskretne.
<p>
Vrste neuronskih mreža podeljene prema vrsti uèenja i pravcu prostiranje signala:
<p>1. NENADGLEDANO UÈENJE
<blockquote><b>A) Feedback mreže</b>
<br>1) Aditivna Grossbergova - Additive Grossberg (AG)
<br>2) Grossbergova sa odlaganjem - Shunting Grossberg (SG)
<br>3) Teorija binarne adaptivne rezonancije - Binary Adaptive Resonance Theory (ART1)
<br>4) Teorija analogne adaptivne rezonancije - Analog Adaptive Resonance Theory (ART2, ART2a)
<br>5) Diskretna Hopfildova - Discrete Hopfield (DH)
<br>6) Kontinualna Hopfildova - Continuous Hopfield (CH)
<br>7) Diskretna bidirekciona asocijativna memorija - Discrete Bidirectional Associative Memory (BAM)
<br>8) Privremena asocijativna memorija - Temporal Associative Memory (TAM)
<br>9) Adaptivna bidirekciona asocijativna memorija - Adaptive Bidirectional Associative Memory (ABAM)
<br>10) Kohenove samoorganizujuæe mape - Kohonen Self-organizing Map/Topology-preserving map (SOM/TPM)
<br>11) Kompetitivno uèenje - Competitive learning
<p><b>B) Feedforward - mreže:</b>
<br>1) Matrice sa moguænošæu uèenja- Learning Matrix (LM)
<br>2) Pobuðeno-primorano uèenje - Driver-Reinforcement Learning (DR)
<br>3) Linearna asocijativna memorija - Linear Associative Memory (LAM)
<br>4) Optimizovana linearna asocijativna memorija - Optimal Linear Associative Memory (OLAM)
<br>5) Slabo rasporeðena distribuirana asocijativna memorija - Sparse Distributed Associative Memory (SDM)
<br>6) Fuzzy ascocijativna memorija - Fuzzy Associative Memory (FAM)
<br>7) Counterpropagation (CPN)</blockquote>

2. NADGLEDANO UÈENJE
<blockquote><b>
A) Feedback mreže</b>
<br>1) Brain-State-in-a-Box (BSB)
<br>2) Fuzzy kongitivne mape - Fuzzy Congitive Map (FCM)
<br>3) Bolcmanova mašina - Boltzmann Machine (BM)
<br>4) Mean Field Annealing (MFT)
<br>5) Rekurzivno kaskadno povezivanje - Recurrent Cascade Correlation (RCC)
<br>6) Povratna propagacija kroz vreme - Backpropagation through time (BPTT)
<br>7) Povratno uèenje u realnom vremenu - Real-time recurrent learning (RTRL)
<br>8) Recurrent Extended Kalman Filter (EKF)
<p><b>B) Feedforward-mreže:</b>
<br>1) Perceptron
<br>2) Adaline, Madaline
<br>3) Backpropagation (BP)
<br>4) Košijeva mašina - Cauchy Machine (CM)
<br>5) Adaptivni heuristièki kriterijum -
Adaptive Heuristic Critic (AHC)
<br>6) NM sa vremenskim zadržavanjem - Time Delay Neural Network (TDNN)
<br>7) Asocijativno nagraðivanje - Associative Reward Penalty (ARP)
<br>8) Avalanche Matched Filter (AMF)
<br>9) Backpercolation (Perc)
<br>10) Artmap
<br>11) Adaptivne logièke mreže - Adaptive Logic Network (ALN)
<br>12) Kaskadne veze- Cascade Correlation (CasCor)
<br>13) Prošireni Kalman-ov filter - Extended Kalman Filter(EKF)
<br>14) Kvantizacija vektora uèenja - Learning Vector Quantization (LVQ)
<br>15) NM zasnovane na verovatnoæi- Probabilistic Neural Network (PNN)
<br>16) Opšte regresione NM - General Regression Neural Network (GRNN)
</blockquote>


<table class="header_large" width="450" border="0"><tbody><tr><td cellpadding="10" cellspacing="10" align="left">
<a NAME="Mogucnosti"></a>Moguænosti neuronskih mreža
</td></tr></tbody></table>

Teoretski se NM mogu obuèiti za izraèunavanje svake izraèunljive funkcije. One mogu uraditi sve što može normalan digitalan
raèunar da uradi. 

<p>Meðutim u praksi, NM najbolje rezultate pokazuju na podruèju klasifikacije, funkcije aproksimacije, na problemima mapiranja èija je tolerancija neprecizna, na problemima koji imaju dosta dostupnih podataka za trening ili na problemima koji zahtevaju brzu primenu
odgovarajuæeg pravila u zavisnosti od ulaznih podataka. Isto tako mapiranje vektora izmeðu prostora može se aproksimirati precizno putem NM. NM ne mogu da stvore informaciju koju ne sadrže trening podaci.
<br>

<table class="header_large" width="450" border="0"><tbody><tr><td cellpadding="10" cellspacing="10" align="left">
<a NAME="Razlike"></a>Razlike izmeðu neuronskih mreža i klasiènih raèunara
</td></tr></tbody></table>

Neuronska mreža se razlikuje od tradicionalnih raèunara (PC raèunara, radnih stanica, i mainframe raèunara) u formi i funkcionisanju. Dok neuronska mreža koristi veliki broj jednostavnih procesora da bi obavila njene kalkulacije, tradicionalni raèunari koriste jedan ili,
u reðim sluèajevima, svega nekoliko veoma kompleksnih procesorskih jedinica. Neuronska mreža ne poseduje centralno lokalizovanu memoriju, niti se programira sekvencama instrukcija, kao svi tradicionalni raèunari. 

<p>Klasièni raèunari koji rade na binarnoj logièkoj osnovi, koriste algoritamski naèin obrade podataka (sekvencijalni) sa veoma niskim stepenom paralelizacije. U algoritamskom naèinu obrade podataka raèunar obraðuje jednu po jednu informaciju ili u boljem sluèaju obraðuje manji broj informacija u isto vreme. Za razliku od ovog pristupa obrade podataka, NM procesira istovremeno više informacija, tj. najbolja
varijanta za NM je da je svaki neuron po jedan procesor. Razvoj NM je doveo do novih arhitektura raèunara koji se u mnogome razlikuju od raèunara kakvi su danas rasprostranjeni. Ako bismo posmatrali primer prepoznavanja slova, algoritamsko rešenje bi zahtevalo da se zadato slovo uporedi sa svim slovima u bazi, slovo po slovo, dok NM može da uporedi zadato slovo istovremeno sa svim slovima, a rešenje je slovo sa najveæom verovatnoæom. Ovo je moguæe jer se memoriji pristupa uz pomoæ sadržaja, a ne adrese. 

<p>Kod klasiènih raèunara su elementi obrade informacija i elementi memorisanja informacija potpuno odvojene komponente. Kod neuronske mreže memorisanje i obrada predstavljaju jednu kompaktnu celinu. Podaci koji su vezani za rad neuronske mreže nemaju nikakav smisao bez jedinica obrade. 

<p>Neuronska mreža se razlikuje od tradicionalnih raèunara po naèinu na koji se “programira”. Umesto programa napisanih kao serije instrukcija, kao što to rade klasièni raèunari, može se upotrebiti obuèena NM, gde arhitektura i težinski koeficijenti odreðuju njenu funkciju. Koeficijenti se podešavaju tokom obuèavanja na ogranièenom skupu karakteristiènih primera. Kada se mreža obuèi do zadovoljavajuæe granice, vrednosti veza se mogu memorisati i koristiti u kasnijem radu.

<p>Kod klasiènih raèunara softver mora biti gotovo savršen da bi radio. Razvoj softvera zahteva iscrpan dizajn, testiranje i postepeno usavršavanje èine ga dugim i skupim procesom. NM omoguæavaju evolutivni razvoj softvera, tj. NM mreža se može naknadno adaptirati realnim
i novo nastalim uslovima. Neuronske mreže imaju sposobnost da menjaju svoju strukturu i funkciju, za razliku od klasiènih algoritama koji nemaju toliku fleksibilnost.

<p>Decentralizovana obrada i memorisanje omoguæavaju mreži da nastavi funkcionisanje i u uslovima kada se deo mreže ošteti (jedan deo neurona prestane da funkcioniše ili se neke veze prekinu). Ošteæena mreža æe i dalje biti u stanju da funkcioniše ali sa smanjenom taènošæu. Mreža je takoðe tolerantna i na prisustvo šuma u ulaznom signalu. Svaki memorisani uzorak je delokalizovan, tj. smešten je u celu mrežu. Ova osobina je još jedna veoma važna osobina NM.
<br>

<table class="header_large" width="450" border="0"><tbody><tr><td cellpadding="10" cellspacing="10" align="left">
<a NAME="Nacini implementacije"></a>Naèini implementacije neuronskih mreža
</td></tr></tbody></table>


Neuronske mreže su obièno simulirane na tradicionalnim raèunarima. Prednost ovog pristupa je u tome što se raèunari mogu lako reprogramirati da promene arhitekturu ili pravilo uèenja simulirane neuronske mreže. Raèunanje u neuronskoj mreži je uglavnom paralelno, tako da brzina obrade simulirane neuronske mreže može biti znatno uveæana korišæenjem paralelnih procesora.
<p>

NM i klasièno programiranje mogu se posmatrati kao fundamentalno razlièiti, ali komplementarni prilazi obradi informacija.
NM su zasnovane na transformacijama, dok je programiranje zasnovano na algoritmima i pravilima.
<br>

<table class="header_large" width="450" border="0"><tbody><tr><td cellpadding="10" cellspacing="10" align="left">
<a NAME="Domeni"></a>Domeni primene
</td></tr></tbody></table>


<p>U poèetku su NM koristili nauènici raèunarskih i kognitivnih nauka koji su pokušavali da modeliraju èulni sistem živih organizama. Danas neuronske mreže predstavljaju veoma atraktivnu oblast istraživanja i postoje brojne oblasti u kojima se koriste. Primenjuju
se za:

<ul>
<li>prepoznavanje oblika,</li>
<li>prepoznavanje rukopisa,</li>
<li>prepoznavanje govora,</li>
<li>finansijske i ekonomske modele,</li>
<li>predviðanje kretanja cena na tržištu,</li>
<li>upravljanje sistemima,</li>
<li>upravljanje proizvodnim procesima,</li>
<li>analizu elektriènih kola,</li>
<li>psihijatrijske procene,</li>
<li>kompresovanje podataka,</li>
<li>naftna istraživanja,</li>
<li>kriminološka istraživanja,</li>
<li>analizu medicinskih testova,</li>
<li>ispitivanje EEG i EKG signala,</li>
<li>pronalaženje optimalnog rešenja,</li>
<li>upravljanje robotima,</li>
<li>analiziranje podataka pri pirolizi i spektroskopiji,</li>
<li>u bioraèunarskim sistemima,</li>
<li>vremensku prognozu i</li>
<li>u drugima oblastima.</li>
</ul>

Primenu neuronskih mreža je moguæe podeliti na tri karakteristiène oblasti:
<ul>
<li>procesiranje senzorskih informacija</li>
<li>analiza podataka</li>
<li>kontrola upravljanja</li>
</ul>

Konkretana primena neuronskih mreža se može videti preko dva realizovana programa (program za prepoznavanje æiriliènih slova <a href="ocr.html">OCR</a>, program za obuèavanje neuronskih mreža <a href="ANN.html">ANN</a>).

<br>
</td>

<td valign="top" width="150" class="menu2"> <!--main right or menu-->

<a href="http://translate.google.com/translate?prev=_t&hl=en&ie=UTF-8&u=http%3A%2F%2Fsolair.eunet.rs%2F%7Eilicv%2Fneuro.html&sl=sr&tl=en"><img SRC="en.gif" height=20 width=39> <font face="Arial,Helvetica"size=-2><br>English version<br>(Google Translate)</a>

<br>
<br>


<table BORDER CELLSPACING=0 CELLPADDING=0 WIDTH="100%" BGCOLOR="#F0F0F0" >
<tr>
<td>
<center>Povezano sa:</center>
</td>
</tr>
</table>
</font>
<a href="ocr.html">OCR</a>
<p><a href="ocr_opis.html">OCR - prep. æiriliènih slova</a>
<p><a href="ANN.html">ANN</a>
<p><a href="NeuroVCL.html">NeuroVCL</a>
<p><a href="AI_index.htm">Veštaèka inteligecija</a>
<p><a href="FLAlg.html">Force learn algorithm</a>
<p><a href="agenti.html">Softverski agenti</a>
<p><a href="enaa.html">ENAA</a>

<br>
<br>
<br><hr>
<p>
<!-- Place this tag in your head or just before your close body tag -->
<script type="text/javascript" src="https://apis.google.com/js/plusone.js"></script>

<!-- Place this tag where you want the +1 button to render -->
<g:plusone size="medium" href="http://SOLAIR.EUnet.rs/~ilicv/neuro.html"></g:plusone>


</td></tr></tbody></table>
</td></tr></tbody></table>





</td></tr>









</tbody></table>
</td></tr></tbody></table>


<table width="100%">
  <tbody><tr align="center">
    <td class="footer" align="right">
	  <hr>
<table width="100%">
<tbody><tr><td align="left">
Page url: <a href="http://SOLAIR.EUnet.rs/~ilicv/neuro.html">http://SOLAIR.EUnet.rs/~ilicv/neuro.html</a></td>
<td align="right">
Web design by: <a href="http://solair.eunet.rs/%7Eilicv/">Velibor Ilic</a>
</td></tr></tbody></table>

</td></tr></tbody></table>
</td></tr></tbody></table>
<td width="30"></td></tr>
</tbody></table>

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
var pageTracker = _gat._getTracker("UA-11148888-1");
pageTracker._trackPageview();
} catch(err) {}</script>

</center></body></html>
